{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hacktherealty1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQRAM2YTjI7U",
        "outputId": "6b4ed38e-343a-4c7b-cf3e-e530c954251e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjwEmSXuySNu",
        "outputId": "bf942497-51ed-4d1b-b7bc-014ec7f606bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/HackTheRealty.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/HackTheRealty.zip\n",
            "  inflating: HackTheRealty/E/exposition_sample_submission.tsv  \n",
            "  inflating: HackTheRealty/E/exposition_test.tsv  \n",
            "  inflating: HackTheRealty/E/exposition_train.tsv  \n",
            "  inflating: HackTheRealty/E/fields_exposition_train.md  \n",
            "  inflating: HackTheRealty/P/fields_price_housebase.md  \n",
            "  inflating: HackTheRealty/P/fields_price_train.md  \n",
            "  inflating: HackTheRealty/P/price_housebase.tsv  \n",
            "  inflating: HackTheRealty/P/price_sample_submission.tsv  \n",
            "  inflating: HackTheRealty/P/price_test.tsv  \n",
            "  inflating: HackTheRealty/P/price_train.tsv  \n",
            "  inflating: HackTheRealty/quadkey.py  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Glb42pw-8gNt",
        "outputId": "2f3145fb-d3e7-47e4-eda4-dfada3ff5a0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "ls HackTheRealty/E"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "exposition_sample_submission.tsv  exposition_train.tsv\n",
            "exposition_test.tsv               fields_exposition_train.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpsw5oPK87i7",
        "outputId": "41df81c8-e573-4f07-88f5-8c278fab59b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def train_lgb(X_, X_val, Y_, Y_val):\n",
        "    categ_nums = Y_.unique().shape[0] + 1\n",
        "    objective = \"multiclass\"\n",
        "    params = {\n",
        "        \"objective\": objective,\n",
        "        'max_depth': 5,\n",
        "        'num_leaves': 20,\n",
        "        'colsample_bytre': 0.1,\n",
        "        \"subsample\": 0.1,\n",
        "        \"learning_rate\": 0.01,\n",
        "        'n_estimators': 200,\n",
        "        'num_trees': 5000,\n",
        "        'num_class': categ_nums,\n",
        "        'early_stopping_rounds': 100,\n",
        "        'verbose': 100\n",
        "    }\n",
        "\n",
        "    lgtrain = lgb.Dataset(X_, Y_)\n",
        "    lgval = lgb.Dataset(X_val, Y_val)\n",
        "    gbm = lgb.train(params, lgtrain, 2000, valid_sets=[lgtrain, lgval], verbose_eval = 100)\n",
        "    preds = gbm.predict(X_val)\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "    print(\"preds\", preds[:10])\n",
        "    print(\"y_val\", Y_val[:10])\n",
        "    try:\n",
        "        print(\"accuracy_score\", accuracy_score(Y_val, preds))\n",
        "        print(\"f1_score\", f1_score(Y_val, preds))\n",
        "    except:\n",
        "        pass\n",
        "    return gbm\n",
        "\n",
        "\n",
        "train = pd.read_csv(\"HackTheRealty/E/exposition_train.tsv\", sep=\"\\t\")\n",
        "test = pd.read_csv(\"HackTheRealty/E/exposition_test.tsv\", sep=\"\\t\")\n",
        "\n",
        "del_cols = {\"id\", \"target_string\", \"main_image\", \"building_id\", \"unified_address\"}\n",
        "cat_cols = {\"parking\", \"day\", \"building_type\", \"balcony\", \"locality_name\", \"renovation\", \"public\"}\n",
        "\n",
        "def clean_df(df):\n",
        "    df = df[[c for c in df.columns if c not in del_cols]]\n",
        "    for col in df.columns:\n",
        "        if col == \"target\":\n",
        "            continue\n",
        "        df[col] = df[col].fillna(-1)\n",
        "    for col in cat_cols:\n",
        "        df[col] = df[col].astype('category')\n",
        "    return df\n",
        "\n",
        "test[\"target\"] = None\n",
        "df = pd.concat([train, test])\n",
        "df = clean_df(df)\n",
        "\n",
        "train, test = df[~df[\"target\"].isna()], df[df[\"target\"].isna()]\n",
        "test = test[[c for c in test.columns if c != \"target\"]]\n",
        "train, valid = train_test_split(train, test_size=0.2, random_state=42)\n",
        "\n",
        "train_X, train_Y = train[[c for c in train.columns if c != \"target\"]], train[\"target\"]\n",
        "valid_X, valid_Y = valid[[c for c in valid.columns if c != \"target\"]], valid[\"target\"]\n",
        "train_Y = train_Y.astype(int)\n",
        "valid_Y = valid_Y.astype(int)\n",
        "gbm = train_lgb(train_X, valid_X, train_Y, valid_Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:123: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
            "  warnings.warn('categorical_feature in param dict is overridden.')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's multi_logloss: 1.48603\tvalid_1's multi_logloss: 1.49428\n",
            "[200]\ttraining's multi_logloss: 1.44271\tvalid_1's multi_logloss: 1.4576\n",
            "[300]\ttraining's multi_logloss: 1.41856\tvalid_1's multi_logloss: 1.43952\n",
            "[400]\ttraining's multi_logloss: 1.40279\tvalid_1's multi_logloss: 1.42916\n",
            "[500]\ttraining's multi_logloss: 1.39175\tvalid_1's multi_logloss: 1.42329\n",
            "[600]\ttraining's multi_logloss: 1.38266\tvalid_1's multi_logloss: 1.41904\n",
            "[700]\ttraining's multi_logloss: 1.37469\tvalid_1's multi_logloss: 1.41569\n",
            "[800]\ttraining's multi_logloss: 1.36807\tvalid_1's multi_logloss: 1.41323\n",
            "[900]\ttraining's multi_logloss: 1.36192\tvalid_1's multi_logloss: 1.41116\n",
            "[1000]\ttraining's multi_logloss: 1.35621\tvalid_1's multi_logloss: 1.40949\n",
            "[1100]\ttraining's multi_logloss: 1.35053\tvalid_1's multi_logloss: 1.40795\n",
            "[1200]\ttraining's multi_logloss: 1.34509\tvalid_1's multi_logloss: 1.40661\n",
            "[1300]\ttraining's multi_logloss: 1.33985\tvalid_1's multi_logloss: 1.40544\n",
            "[1400]\ttraining's multi_logloss: 1.33497\tvalid_1's multi_logloss: 1.40453\n",
            "[1500]\ttraining's multi_logloss: 1.33029\tvalid_1's multi_logloss: 1.40389\n",
            "[1600]\ttraining's multi_logloss: 1.32584\tvalid_1's multi_logloss: 1.40331\n",
            "[1700]\ttraining's multi_logloss: 1.32151\tvalid_1's multi_logloss: 1.40283\n",
            "[1800]\ttraining's multi_logloss: 1.31718\tvalid_1's multi_logloss: 1.40243\n",
            "[1900]\ttraining's multi_logloss: 1.31306\tvalid_1's multi_logloss: 1.4021\n",
            "[2000]\ttraining's multi_logloss: 1.309\tvalid_1's multi_logloss: 1.40183\n",
            "[2100]\ttraining's multi_logloss: 1.30513\tvalid_1's multi_logloss: 1.40166\n",
            "[2200]\ttraining's multi_logloss: 1.30136\tvalid_1's multi_logloss: 1.40153\n",
            "[2300]\ttraining's multi_logloss: 1.2978\tvalid_1's multi_logloss: 1.40148\n",
            "[2400]\ttraining's multi_logloss: 1.29431\tvalid_1's multi_logloss: 1.40142\n",
            "[2500]\ttraining's multi_logloss: 1.29075\tvalid_1's multi_logloss: 1.40132\n",
            "Early stopping, best iteration is:\n",
            "[2459]\ttraining's multi_logloss: 1.29216\tvalid_1's multi_logloss: 1.40131\n",
            "preds [3 1 5 2 5 1 2 2 2 1]\n",
            "y_val 272468    3\n",
            "140750    2\n",
            "53477     2\n",
            "235733    2\n",
            "148924    1\n",
            "326508    3\n",
            "163889    3\n",
            "63217     2\n",
            "296137    2\n",
            "125881    2\n",
            "Name: target, dtype: int64\n",
            "accuracy_score 0.40274894810659184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLRu-VHdeC_i"
      },
      "source": [
        "test_preds = np.argmax(gbm.predict(test), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P708LMpufU0N"
      },
      "source": [
        "submission = pd.read_csv(\"HackTheRealty/E/exposition_sample_submission.tsv\", sep=\"\\t\")\n",
        "submission[\"target\"] = test_preds\n",
        "submission.to_csv(\"submission_e2.tsv\",index=None, sep=\"\\t\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}